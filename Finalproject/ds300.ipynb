{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-30T14:05:45.292417Z",
     "iopub.status.busy": "2025-11-30T14:05:45.291739Z",
     "iopub.status.idle": "2025-11-30T14:05:45.296919Z",
     "shell.execute_reply": "2025-11-30T14:05:45.295906Z",
     "shell.execute_reply.started": "2025-11-30T14:05:45.292385Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PROJECT\\DS300\\ds300_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:11:32.649245Z",
     "iopub.status.busy": "2025-11-30T14:11:32.648859Z",
     "iopub.status.idle": "2025-11-30T14:11:32.657049Z",
     "shell.execute_reply": "2025-11-30T14:11:32.656068Z",
     "shell.execute_reply.started": "2025-11-30T14:11:32.649203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====== CONFIG ======\n",
    "genai.configure(api_key=\"AIzaSyD9YZ2PQvjHbdXyN02Rm5IWyhnv9Y2Cnhg\")\n",
    "MODEL = \"models/gemini-2.5-flash\"\n",
    "\n",
    "STATE_FILE = \"dialog_state.json\"\n",
    "\n",
    "# ====== INIT EMPTY STATE IF NOT EXIST ======\n",
    "DEFAULT_STATE = {\n",
    "    \"hard_constraints\": {\n",
    "        \"cuisine_type\": [],\n",
    "        \"dish_type\": [],\n",
    "        \"price_range\": [],\n",
    "        \"location\": []\n",
    "    },\n",
    "    \"soft_constraints\": {\n",
    "        \"atmosphere\": [],\n",
    "        \"others\": []\n",
    "    },\n",
    "    \"recommended_items\": [],\n",
    "    \"accepted_items\": [],\n",
    "    \"rejected_items\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:05:45.317897Z",
     "iopub.status.busy": "2025-11-30T14:05:45.317619Z",
     "iopub.status.idle": "2025-11-30T14:05:45.333809Z",
     "shell.execute_reply": "2025-11-30T14:05:45.332982Z",
     "shell.execute_reply.started": "2025-11-30T14:05:45.317875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_state():\n",
    "    if Path(STATE_FILE).exists():\n",
    "        return json.load(open(STATE_FILE, \"r\", encoding=\"utf-8\"))\n",
    "    else:\n",
    "        json.dump(DEFAULT_STATE, open(STATE_FILE, \"w\", encoding=\"utf-8\"), indent=4)\n",
    "        return DEFAULT_STATE\n",
    "\n",
    "\n",
    "def save_state(state):\n",
    "    json.dump(state, open(STATE_FILE, \"w\", encoding=\"utf-8\"), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:05:45.335979Z",
     "iopub.status.busy": "2025-11-30T14:05:45.335622Z",
     "iopub.status.idle": "2025-11-30T14:05:45.349097Z",
     "shell.execute_reply": "2025-11-30T14:05:45.348334Z",
     "shell.execute_reply.started": "2025-11-30T14:05:45.335955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. INTENT CLASSIFICATION (Provide Preference, Inquire, Accept, Reject)\n",
    "# ============================================================\n",
    "\n",
    "def classify_intent(user_prompt):\n",
    "    prompt = f\"\"\"\n",
    "Classify the user's INTENT in a conversational recommender system.\n",
    "\n",
    "Possible intents (can have multiple):\n",
    "- \"Provide Preference\" - user states what they want (cuisine, location, price, atmosphere, dish type)\n",
    "- \"Inquire\" - user asks a question\n",
    "- \"Accept Recommendation\" - user accepts a suggested item\n",
    "- \"Reject Recommendation\" - user rejects a suggested item\n",
    "\n",
    "Examples:\n",
    "- \"I'm looking for Japanese sushi restaurant\" → [\"Provide Preference\"]\n",
    "- \"I want Italian food in downtown\" → [\"Provide Preference\"]\n",
    "- \"What do you recommend?\" → [\"Inquire\"]\n",
    "- \"I'll take that one\" → [\"Accept Recommendation\"]\n",
    "- \"No, I don't like that\" → [\"Reject Recommendation\"]\n",
    "\n",
    "User: \"{user_prompt}\"\n",
    "\n",
    "Return ONLY a JSON array of intent strings (e.g., [\"Provide Preference\"]).\n",
    "\"\"\"\n",
    "    resp = genai.GenerativeModel(MODEL).generate_content(prompt)\n",
    "\n",
    "    try:\n",
    "        text = resp.text.strip()\n",
    "        # Remove markdown code blocks if present\n",
    "        if \"```\" in text:\n",
    "            # Extract content between ``` markers\n",
    "            parts = text.split(\"```\")\n",
    "            if len(parts) >= 2:\n",
    "                text = parts[1]\n",
    "                # Remove language identifier if present\n",
    "                if text.startswith(\"json\"):\n",
    "                    text = text[4:]\n",
    "                text = text.strip()\n",
    "        \n",
    "        # Remove any leading/trailing whitespace and newlines\n",
    "        text = text.strip()\n",
    "        return json.loads(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing intent JSON: {e}\")\n",
    "        print(f\"Response: {resp.text}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:05:45.350198Z",
     "iopub.status.busy": "2025-11-30T14:05:45.349971Z",
     "iopub.status.idle": "2025-11-30T14:05:45.368654Z",
     "shell.execute_reply": "2025-11-30T14:05:45.367813Z",
     "shell.execute_reply.started": "2025-11-30T14:05:45.350178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. STATE UPDATE USING LLM\n",
    "# ============================================================\n",
    "\n",
    "def update_state(user_prompt, intents, state):\n",
    "    # ---- Update Preferences ----\n",
    "    if \"Provide Preference\" in intents:\n",
    "        prompt = f\"\"\"\n",
    "You update a JSON dialogue state based on user preferences.\n",
    "\n",
    "User said: \"{user_prompt}\"\n",
    "\n",
    "Current JSON:\n",
    "{json.dumps(state, indent=4)}\n",
    "\n",
    "Rules:\n",
    "- Extract cuisine_type, dish_type, atmosphere, price, or any preference.\n",
    "- Put strict requirements into hard_constraints.\n",
    "- Put optional ones into soft_constraints.\n",
    "- Format correctly.\n",
    "- Maintain the existing structure with all required fields.\n",
    "\n",
    "Return ONLY the new updated JSON.\n",
    "\"\"\"\n",
    "        resp = genai.GenerativeModel(MODEL).generate_content(prompt)\n",
    "\n",
    "        try:\n",
    "            # Remove markdown code blocks if present\n",
    "            text = resp.text.strip()\n",
    "            if \"```\" in text:\n",
    "                # Extract content between ``` markers\n",
    "                parts = text.split(\"```\")\n",
    "                if len(parts) >= 2:\n",
    "                    text = parts[1]\n",
    "                    # Remove language identifier if present\n",
    "                    if text.startswith(\"json\"):\n",
    "                        text = text[4:]\n",
    "                    text = text.strip()\n",
    "            # Remove any leading/trailing whitespace\n",
    "            text = text.strip()\n",
    "            \n",
    "            new_state = json.loads(text)\n",
    "            state = new_state\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "            print(f\"Response text: {resp.text[:200]}...\")  # Show first 200 chars\n",
    "\n",
    "    # ---- Accept Recommendation ----\n",
    "    if \"Accept Recommendation\" in intents:\n",
    "        ask = f\"Extract the item name the user accepted from: '{user_prompt}'. Return plain text only.\"\n",
    "        item = genai.GenerativeModel(MODEL).generate_content(ask).text.strip()\n",
    "        if item:\n",
    "            state[\"accepted_items\"].append(item)\n",
    "\n",
    "    # ---- Reject Recommendation ----\n",
    "    if \"Reject Recommendation\" in intents:\n",
    "        ask = f\"Extract the item name the user rejected from: '{user_prompt}'. Return plain text only.\"\n",
    "        item = genai.GenerativeModel(MODEL).generate_content(ask).text.strip()\n",
    "        if item:\n",
    "            state[\"rejected_items\"].append(item)\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:05:45.370264Z",
     "iopub.status.busy": "2025-11-30T14:05:45.369665Z",
     "iopub.status.idle": "2025-11-30T14:05:45.390529Z",
     "shell.execute_reply": "2025-11-30T14:05:45.389637Z",
     "shell.execute_reply.started": "2025-11-30T14:05:45.370237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. ACTION SELECTION\n",
    "# ============================================================\n",
    "\n",
    "def select_action(intents, state):\n",
    "    # If user asks a question:\n",
    "    if \"Inquire\" in intents:\n",
    "        return \"Answer\"\n",
    "\n",
    "    # Check all hard_constraints for missing values\n",
    "    for key in state[\"hard_constraints\"]:\n",
    "        if len(state[\"hard_constraints\"][key]) == 0:\n",
    "            return \"Request Hard Constraint\"\n",
    "    \n",
    "    # All hard constraints filled, check soft constraints\n",
    "    all_soft_empty = all(len(state[\"soft_constraints\"][key]) == 0 for key in state[\"soft_constraints\"])\n",
    "    \n",
    "    if all_soft_empty:\n",
    "        return \"Request Soft Constraint\"\n",
    "    \n",
    "\n",
    "    # Everything filled → recommend\n",
    "    return \"Recommend and Explain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:05:45.391995Z",
     "iopub.status.busy": "2025-11-30T14:05:45.391493Z",
     "iopub.status.idle": "2025-11-30T14:05:45.412223Z",
     "shell.execute_reply": "2025-11-30T14:05:45.411288Z",
     "shell.execute_reply.started": "2025-11-30T14:05:45.391968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. GENERATE RESPONSE (Answer / Request Info / Recommend)\n",
    "# ============================================================\n",
    "\n",
    "def generate_bot_response(user_prompt, action, state):\n",
    "    if action == \"Request Hard Constraint\":\n",
    "        # Find first missing hard constraint and ask\n",
    "        for key in state[\"hard_constraints\"]:\n",
    "            if len(state[\"hard_constraints\"][key]) == 0:\n",
    "                key_display = key.replace(\"_\", \" \").title()\n",
    "                return f\"What {key_display} do you prefer?\"\n",
    "        return \"I need more information to help you.\"\n",
    "    \n",
    "    elif action == \"Request Soft Constraint\":\n",
    "        # Ask about soft constraints\n",
    "        soft_keys = [key.replace(\"_\", \" \") for key in state[\"soft_constraints\"].keys()]\n",
    "        soft_list = \", \".join(soft_keys)\n",
    "        return f\"Do you have any preferences about: {soft_list}? (or say 'no' to skip)\"\n",
    "\n",
    "    elif action == \"Answer\":\n",
    "        prompt = f\"\"\"\n",
    "User asks: \"{user_prompt}\"\n",
    "\n",
    "State:\n",
    "{json.dumps(state, indent=4)}\n",
    "\n",
    "Generate an informational answer based on preferences and context.\n",
    "\"\"\"\n",
    "        return genai.GenerativeModel(MODEL).generate_content(prompt).text\n",
    "\n",
    "    elif action == \"Recommend and Explain\":\n",
    "        prompt = f\"\"\"\n",
    "Based on this state:\n",
    "{json.dumps(state, indent=4)}\n",
    "\n",
    "User said: \"{user_prompt}\"\n",
    "\n",
    "Recommend ONE restaurant and explain why it matches user preferences.\n",
    "Use natural language.\n",
    "\"\"\"\n",
    "        reply = genai.GenerativeModel(MODEL).generate_content(prompt).text\n",
    "        state[\"recommended_items\"] = [\"Your Recommended Item\"]  # demo placeholder\n",
    "        return reply\n",
    "    \n",
    "    return \"I did not understand.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:11:40.095709Z",
     "iopub.status.busy": "2025-11-30T14:11:40.095356Z",
     "iopub.status.idle": "2025-11-30T14:12:01.621897Z",
     "shell.execute_reply": "2025-11-30T14:12:01.620729Z",
     "shell.execute_reply.started": "2025-11-30T14:11:40.095683Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RA-Rec Style Conversational Recommender (Gemini) ===\n",
      "\n",
      "State reset to default.\n",
      "\n",
      "BOT: Hello! I'm here to help you find a great restaurant. What type of cuisine are you interested in?\n",
      "\n",
      "BOT: What Price Range do you prefer?\n",
      "\n",
      "BOT: What Price Range do you prefer?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Prevent multiple executions\n",
    "if 'chatbot_running' in globals():\n",
    "    print(\"Chatbot is already running. Please restart kernel to run again.\")\n",
    "    sys.exit()\n",
    "\n",
    "chatbot_running = True\n",
    "\n",
    "print(\"=== RA-Rec Style Conversational Recommender (Gemini) ===\\n\")\n",
    "\n",
    "# Reset state to empty at the beginning of each run\n",
    "with open(STATE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(DEFAULT_STATE, f, indent=4, ensure_ascii=False)\n",
    "print(\"State reset to default.\\n\")\n",
    "\n",
    "# Initial greeting from bot\n",
    "print(\"BOT: Hello! I'm here to help you find a great restaurant. What type of cuisine are you interested in?\\n\")\n",
    "\n",
    "while True:\n",
    "    user_prompt = input(\"USER: \")\n",
    "\n",
    "    if user_prompt.lower() == \"exit\" or user_prompt.lower() == \"stop\":\n",
    "        break\n",
    "\n",
    "    state = load_state()\n",
    "\n",
    "    # Step 1: Classify intent\n",
    "    intents = classify_intent(user_prompt)\n",
    "    \n",
    "    # Check if user rejects soft constraint (says \"no\", \"skip\", \"no preference\")\n",
    "    if any(word in user_prompt.lower() for word in [\"no\", \"skip\", \"nope\", \"don't\", \"dont\"]):\n",
    "        # Check if all hard constraints are filled\n",
    "        all_hard_filled = all(len(state[\"hard_constraints\"][key]) > 0 for key in state[\"hard_constraints\"])\n",
    "        if all_hard_filled:\n",
    "            # User declined soft constraints, go straight to recommend\n",
    "            action = \"Recommend and Explain\"\n",
    "            reply = generate_bot_response(user_prompt, action, state)\n",
    "            print(f\"BOT: {reply}\\n\")\n",
    "            continue\n",
    "\n",
    "    # Step 2: Update state\n",
    "    state = update_state(user_prompt, intents, state)\n",
    "    save_state(state)\n",
    "\n",
    "    # Step 3: Select action\n",
    "    action = select_action(intents, state)\n",
    "\n",
    "    # Step 4: Generate response\n",
    "    reply = generate_bot_response(user_prompt, action, state)\n",
    "    print(f\"BOT: {reply}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ds300_env (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
