{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b9777b",
   "metadata": {},
   "source": [
    "## 1. Import Libraries và Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thư viện cần thiết\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TF-IDF và cosine similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
    "\n",
    "# Word Embedding\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7379f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dữ liệu\n",
    "movies_metadata = pd.read_csv('movies/movies_metadata.csv', low_memory=False)\n",
    "ratings = pd.read_csv('movies/ratings.csv')\n",
    "links = pd.read_csv('movies/links.csv')\n",
    "\n",
    "print(f\"Movies metadata shape: {movies_metadata.shape}\")\n",
    "print(f\"Ratings shape: {ratings.shape}\")\n",
    "print(f\"Links shape: {links.shape}\")\n",
    "print(\"\\nMovies metadata sample:\")\n",
    "display(movies_metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2690b",
   "metadata": {},
   "source": [
    "## 2. Lấy 110 phim của UserID = 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lọc ratings của user 201\n",
    "user_201_ratings = ratings[ratings['userId'] == 201].copy()\n",
    "print(f\"Số lượng phim user 201 đã đánh giá: {len(user_201_ratings)}\")\n",
    "print(\"\\nDữ liệu ratings của user 201:\")\n",
    "display(user_201_ratings.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra nếu user 201 có đủ 110 phim\n",
    "if len(user_201_ratings) < 110:\n",
    "    print(f\"WARNING: User 201 chỉ có {len(user_201_ratings)} phim, ít hơn 110 phim yêu cầu!\")\n",
    "    print(\"Sẽ sử dụng tất cả phim có sẵn.\")\n",
    "else:\n",
    "    print(f\"✓ User 201 có {len(user_201_ratings)} phim (>= 110 phim)\")\n",
    "\n",
    "# Sắp xếp theo timestamp để lấy 110 phim đầu tiên\n",
    "user_201_ratings = user_201_ratings.sort_values('timestamp').reset_index(drop=True)\n",
    "user_201_ratings_110 = user_201_ratings.head(110).copy()\n",
    "\n",
    "print(f\"\\nĐã lấy {len(user_201_ratings_110)} phim đầu tiên của user 201\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a9216d",
   "metadata": {},
   "source": [
    "## 3. Chia tập Test (100 phim) và Profile (10 phim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cắt 100 phim đầu làm test set\n",
    "test_set = user_201_ratings_110.head(100).copy()\n",
    "\n",
    "# 10 phim còn lại làm profile set\n",
    "profile_set = user_201_ratings_110.tail(10).copy()\n",
    "\n",
    "print(f\"Test set size: {len(test_set)}\")\n",
    "print(f\"Profile set size: {len(profile_set)}\")\n",
    "\n",
    "print(\"\\n=== Profile Set (10 phim để biểu diễn user 201) ===\")\n",
    "display(profile_set)\n",
    "\n",
    "print(\"\\n=== Test Set (100 phim đầu) ===\")\n",
    "display(test_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ecd3b",
   "metadata": {},
   "source": [
    "## 4. Mapping movieId giữa ratings.csv và movies_metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063063c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge links để chuyển đổi movieId từ ratings sang tmdbId trong movies_metadata\n",
    "# ratings.csv dùng movieId từ MovieLens\n",
    "# movies_metadata.csv dùng id từ TMDB\n",
    "\n",
    "# Clean movies_metadata id column (có thể có giá trị non-numeric)\n",
    "movies_metadata['id'] = pd.to_numeric(movies_metadata['id'], errors='coerce')\n",
    "movies_metadata = movies_metadata.dropna(subset=['id'])\n",
    "movies_metadata['id'] = movies_metadata['id'].astype(int)\n",
    "\n",
    "# Merge links với ratings để có tmdbId\n",
    "profile_movies = profile_set.merge(links[['movieId', 'tmdbId']], on='movieId', how='left')\n",
    "test_movies = test_set.merge(links[['movieId', 'tmdbId']], on='movieId', how='left')\n",
    "\n",
    "print(\"Profile movies with TMDB ID:\")\n",
    "display(profile_movies)\n",
    "\n",
    "# Lấy thông tin metadata cho profile movies\n",
    "profile_movies_metadata = profile_movies.merge(\n",
    "    movies_metadata[['id', 'title', 'overview', 'genres']], \n",
    "    left_on='tmdbId', \n",
    "    right_on='id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nSố phim trong profile có metadata: {len(profile_movies_metadata.dropna(subset=['overview']))}\")\n",
    "display(profile_movies_metadata[['title', 'overview', 'rating']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977f5b5",
   "metadata": {},
   "source": [
    "## 5. Tiền xử lý Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f59703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tiền xử lý text\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Tiền xử lý text: lowercase, remove special chars, remove stopwords\"\"\"\n",
    "    if not isinstance(text, str) or pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Áp dụng preprocessing cho movies_metadata\n",
    "movies_metadata['overview_clean'] = movies_metadata['overview'].apply(preprocess_text)\n",
    "movies_metadata['overview_clean'] = movies_metadata['overview_clean'].fillna('')\n",
    "\n",
    "print(\"Sample preprocessed overviews:\")\n",
    "for idx in range(3):\n",
    "    print(f\"\\nOriginal: {movies_metadata['overview'].iloc[idx][:100]}...\")\n",
    "    print(f\"Cleaned: {movies_metadata['overview_clean'].iloc[idx][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92f3b67",
   "metadata": {},
   "source": [
    "## 6. Tạo User Profile từ 10 phim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de6648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kết hợp overview của 10 phim trong profile set để tạo user profile\n",
    "profile_overviews = profile_movies_metadata.dropna(subset=['overview'])['overview'].values\n",
    "\n",
    "# Tiền xử lý các overview này\n",
    "profile_overviews_clean = [preprocess_text(overview) for overview in profile_overviews]\n",
    "profile_overviews_clean = [ov for ov in profile_overviews_clean if ov]  # Remove empty\n",
    "\n",
    "# Kết hợp tất cả thành một văn bản đại diện cho user 201\n",
    "user_profile_text = ' '.join(profile_overviews_clean)\n",
    "\n",
    "print(f\"Số phim có overview trong profile: {len(profile_overviews_clean)}\")\n",
    "print(f\"\\nUser profile text length: {len(user_profile_text)} characters\")\n",
    "print(f\"\\nUser profile preview (first 500 chars):\\n{user_profile_text[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed3759",
   "metadata": {},
   "source": [
    "## 7. PHƯƠNG PHÁP 1: TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a472b64a",
   "metadata": {},
   "source": [
    "### 7.1. Vector hóa bằng TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4265c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit trên toàn bộ movies corpus\n",
    "tfidf_matrix = tfidf.fit_transform(movies_metadata['overview_clean'])\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Number of features: {len(tfidf.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44322aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform user profile\n",
    "user_profile_tfidf = tfidf.transform([user_profile_text])\n",
    "\n",
    "print(f\"User profile TF-IDF shape: {user_profile_tfidf.shape}\")\n",
    "print(f\"User profile TF-IDF non-zero elements: {user_profile_tfidf.nnz}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498b81e",
   "metadata": {},
   "source": [
    "### 7.2. Tính Cosine Similarity và Recommend Top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính cosine similarity giữa user profile và tất cả movies\n",
    "cosine_similarities_tfidf = cosine_similarity(user_profile_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "# Tạo DataFrame với similarity scores\n",
    "movies_with_scores_tfidf = movies_metadata.copy()\n",
    "movies_with_scores_tfidf['similarity_score'] = cosine_similarities_tfidf\n",
    "\n",
    "# Sắp xếp theo similarity score giảm dần\n",
    "movies_with_scores_tfidf = movies_with_scores_tfidf.sort_values('similarity_score', ascending=False)\n",
    "\n",
    "print(\"Top 10 movies theo TF-IDF similarity:\")\n",
    "display(movies_with_scores_tfidf[['id', 'title', 'similarity_score']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45373f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy top 100 movies được recommend (dự đoán)\n",
    "# Loại bỏ các phim đã có trong profile set\n",
    "profile_movie_ids = set(profile_movies_metadata['id'].dropna().astype(int))\n",
    "\n",
    "# Filter ra các phim không thuộc profile\n",
    "movies_not_in_profile_tfidf = movies_with_scores_tfidf[\n",
    "    ~movies_with_scores_tfidf['id'].isin(profile_movie_ids)\n",
    "]\n",
    "\n",
    "# Lấy top 100\n",
    "top_100_recommendations_tfidf = movies_not_in_profile_tfidf.head(100)\n",
    "\n",
    "print(f\"\\nĐã recommend {len(top_100_recommendations_tfidf)} phim bằng TF-IDF\")\n",
    "print(\"\\nTop 10 recommendations:\")\n",
    "display(top_100_recommendations_tfidf[['id', 'title', 'similarity_score']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06643831",
   "metadata": {},
   "source": [
    "## 8. PHƯƠNG PHÁP 2: Word Embedding (Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ff8a7",
   "metadata": {},
   "source": [
    "### 8.1. Tokenize và Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54baa26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize tất cả overviews\n",
    "def tokenize_text(text):\n",
    "    \"\"\"Tokenize text thành list of words\"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return []\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "# Tokenize toàn bộ corpus\n",
    "print(\"Tokenizing corpus...\")\n",
    "tokenized_corpus = movies_metadata['overview_clean'].apply(tokenize_text).tolist()\n",
    "\n",
    "# Remove empty lists\n",
    "tokenized_corpus = [tokens for tokens in tokenized_corpus if tokens]\n",
    "\n",
    "print(f\"Number of documents: {len(tokenized_corpus)}\")\n",
    "print(f\"Sample tokens: {tokenized_corpus[0][:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cde198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "print(\"Training Word2Vec model...\")\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=tokenized_corpus,\n",
    "    vector_size=100,  # Dimension of word vectors\n",
    "    window=5,         # Context window size\n",
    "    min_count=2,      # Ignore words with frequency < 2\n",
    "    workers=4,        # Number of threads\n",
    "    sg=1,             # Skip-gram model\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "print(f\"\\nWord2Vec model trained!\")\n",
    "print(f\"Vocabulary size: {len(w2v_model.wv)}\")\n",
    "print(f\"Vector dimension: {w2v_model.wv.vector_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c7db1",
   "metadata": {},
   "source": [
    "### 8.2. Tạo Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_vector(tokens, model):\n",
    "    \"\"\"Tạo vector cho document bằng cách average word vectors\"\"\"\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            vectors.append(model.wv[token])\n",
    "    \n",
    "    if not vectors:\n",
    "        return np.zeros(model.wv.vector_size)\n",
    "    \n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Tạo vectors cho tất cả movies\n",
    "print(\"Creating document vectors for all movies...\")\n",
    "movies_metadata['tokens'] = movies_metadata['overview_clean'].apply(tokenize_text)\n",
    "movies_metadata['doc_vector'] = movies_metadata['tokens'].apply(\n",
    "    lambda tokens: get_document_vector(tokens, w2v_model)\n",
    ")\n",
    "\n",
    "print(\"Done! Sample vector shape:\", movies_metadata['doc_vector'].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e676bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo user profile vector từ 10 phim\n",
    "user_profile_tokens = tokenize_text(user_profile_text)\n",
    "user_profile_w2v = get_document_vector(user_profile_tokens, w2v_model)\n",
    "\n",
    "print(f\"User profile W2V shape: {user_profile_w2v.shape}\")\n",
    "print(f\"User profile W2V sample values: {user_profile_w2v[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623340f",
   "metadata": {},
   "source": [
    "### 8.3. Tính Cosine Similarity và Recommend Top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1400ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo matrix từ doc vectors\n",
    "doc_vectors_matrix = np.vstack(movies_metadata['doc_vector'].values)\n",
    "\n",
    "print(f\"Document vectors matrix shape: {doc_vectors_matrix.shape}\")\n",
    "\n",
    "# Tính cosine similarity\n",
    "user_profile_w2v_reshaped = user_profile_w2v.reshape(1, -1)\n",
    "cosine_similarities_w2v = cosine_similarity(user_profile_w2v_reshaped, doc_vectors_matrix).flatten()\n",
    "\n",
    "print(f\"Cosine similarities shape: {cosine_similarities_w2v.shape}\")\n",
    "print(f\"Sample similarities: {cosine_similarities_w2v[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo DataFrame với W2V similarity scores\n",
    "movies_with_scores_w2v = movies_metadata.copy()\n",
    "movies_with_scores_w2v['similarity_score'] = cosine_similarities_w2v\n",
    "\n",
    "# Sắp xếp theo similarity\n",
    "movies_with_scores_w2v = movies_with_scores_w2v.sort_values('similarity_score', ascending=False)\n",
    "\n",
    "print(\"Top 10 movies theo Word2Vec similarity:\")\n",
    "display(movies_with_scores_w2v[['id', 'title', 'similarity_score']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483926ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy top 100 recommendations (loại bỏ profile movies)\n",
    "movies_not_in_profile_w2v = movies_with_scores_w2v[\n",
    "    ~movies_with_scores_w2v['id'].isin(profile_movie_ids)\n",
    "]\n",
    "\n",
    "top_100_recommendations_w2v = movies_not_in_profile_w2v.head(100)\n",
    "\n",
    "print(f\"\\nĐã recommend {len(top_100_recommendations_w2v)} phim bằng Word2Vec\")\n",
    "print(\"\\nTop 10 recommendations:\")\n",
    "display(top_100_recommendations_w2v[['id', 'title', 'similarity_score']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684db982",
   "metadata": {},
   "source": [
    "## 9. Đánh giá: P@K, R@K, F1@K (K=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef05030c",
   "metadata": {},
   "source": [
    "### 9.1. Chuẩn bị Test Set với TMDB IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4695236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy TMDB IDs từ test set\n",
    "test_movies_ids = set(test_movies['tmdbId'].dropna().astype(int))\n",
    "\n",
    "print(f\"Số phim trong test set có TMDB ID: {len(test_movies_ids)}\")\n",
    "print(f\"Sample test movie IDs: {list(test_movies_ids)[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd68e41",
   "metadata": {},
   "source": [
    "### 9.2. Tính Precision@K, Recall@K, F1@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_at_k(recommended_ids, test_ids, k=100):\n",
    "    \"\"\"\n",
    "    Tính Precision@K, Recall@K, F1@K\n",
    "    \n",
    "    Args:\n",
    "        recommended_ids: set of recommended movie IDs\n",
    "        test_ids: set of actual relevant movie IDs (ground truth)\n",
    "        k: number of recommendations\n",
    "    \n",
    "    Returns:\n",
    "        dict with precision, recall, f1\n",
    "    \"\"\"\n",
    "    # Số phim được recommend đúng (có trong test set)\n",
    "    true_positives = len(recommended_ids.intersection(test_ids))\n",
    "    \n",
    "    # Precision@K = TP / K\n",
    "    precision = true_positives / k if k > 0 else 0\n",
    "    \n",
    "    # Recall@K = TP / |test set|\n",
    "    recall = true_positives / len(test_ids) if len(test_ids) > 0 else 0\n",
    "    \n",
    "    # F1@K\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'true_positives': true_positives\n",
    "    }\n",
    "\n",
    "# Test function\n",
    "print(\"Test metrics calculation:\")\n",
    "test_metrics = calculate_metrics_at_k({1,2,3}, {2,3,4,5,6}, k=5)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính metrics cho TF-IDF\n",
    "recommended_ids_tfidf = set(top_100_recommendations_tfidf['id'].astype(int))\n",
    "\n",
    "metrics_tfidf = calculate_metrics_at_k(recommended_ids_tfidf, test_movies_ids, k=100)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"METRICS CHO TF-IDF (K=100)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True Positives: {metrics_tfidf['true_positives']}\")\n",
    "print(f\"Precision@100: {metrics_tfidf['precision']:.4f}\")\n",
    "print(f\"Recall@100: {metrics_tfidf['recall']:.4f}\")\n",
    "print(f\"F1@100: {metrics_tfidf['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc300c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính metrics cho Word2Vec\n",
    "recommended_ids_w2v = set(top_100_recommendations_w2v['id'].astype(int))\n",
    "\n",
    "metrics_w2v = calculate_metrics_at_k(recommended_ids_w2v, test_movies_ids, k=100)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"METRICS CHO WORD2VEC (K=100)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True Positives: {metrics_w2v['true_positives']}\")\n",
    "print(f\"Precision@100: {metrics_w2v['precision']:.4f}\")\n",
    "print(f\"Recall@100: {metrics_w2v['recall']:.4f}\")\n",
    "print(f\"F1@100: {metrics_w2v['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9022a399",
   "metadata": {},
   "source": [
    "## 10. Đánh giá: MRR và NDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975f0fad",
   "metadata": {},
   "source": [
    "### 10.1. Sắp xếp Test Set theo Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231af43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sắp xếp test set theo rating giảm dần\n",
    "test_sorted = test_movies.sort_values('rating', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Test set đã sắp xếp theo rating:\")\n",
    "display(test_sorted[['movieId', 'tmdbId', 'rating', 'timestamp']].head(20))\n",
    "\n",
    "# Tạo list các tmdbId theo thứ tự rating giảm dần\n",
    "test_sorted_ids = test_sorted['tmdbId'].dropna().astype(int).tolist()\n",
    "print(f\"\\nSố phim trong test set có TMDB ID: {len(test_sorted_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebabd27d",
   "metadata": {},
   "source": [
    "### 10.2. Tính MRR (Mean Reciprocal Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e14d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr(recommended_list, relevant_list):\n",
    "    \"\"\"\n",
    "    Tính Mean Reciprocal Rank (MRR)\n",
    "    \n",
    "    Args:\n",
    "        recommended_list: list of recommended movie IDs (theo thứ tự)\n",
    "        relevant_list: list of relevant movie IDs\n",
    "    \n",
    "    Returns:\n",
    "        MRR score\n",
    "    \"\"\"\n",
    "    relevant_set = set(relevant_list)\n",
    "    \n",
    "    for rank, movie_id in enumerate(recommended_list, start=1):\n",
    "        if movie_id in relevant_set:\n",
    "            return 1.0 / rank\n",
    "    \n",
    "    return 0.0\n",
    "\n",
    "# Test\n",
    "test_mrr = calculate_mrr([1, 2, 3, 4, 5], [3])\n",
    "print(f\"Test MRR (relevant at position 3): {test_mrr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67327bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính MRR cho TF-IDF\n",
    "recommended_list_tfidf = top_100_recommendations_tfidf['id'].astype(int).tolist()\n",
    "mrr_tfidf = calculate_mrr(recommended_list_tfidf, test_sorted_ids)\n",
    "\n",
    "print(f\"MRR for TF-IDF: {mrr_tfidf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9dc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính MRR cho Word2Vec\n",
    "recommended_list_w2v = top_100_recommendations_w2v['id'].astype(int).tolist()\n",
    "mrr_w2v = calculate_mrr(recommended_list_w2v, test_sorted_ids)\n",
    "\n",
    "print(f\"MRR for Word2Vec: {mrr_w2v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9198f640",
   "metadata": {},
   "source": [
    "### 10.3. Tính NDCG (Normalized Discounted Cumulative Gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48554708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dcg(recommended_list, relevant_list, k=100):\n",
    "    \"\"\"\n",
    "    Tính DCG@K\n",
    "    Relevance score = 1 nếu có trong relevant_list, 0 nếu không\n",
    "    \"\"\"\n",
    "    relevant_set = set(relevant_list)\n",
    "    dcg = 0.0\n",
    "    \n",
    "    for i, movie_id in enumerate(recommended_list[:k], start=1):\n",
    "        if movie_id in relevant_set:\n",
    "            # Relevance = 1 for relevant items\n",
    "            dcg += 1.0 / np.log2(i + 1)\n",
    "    \n",
    "    return dcg\n",
    "\n",
    "def calculate_ndcg(recommended_list, relevant_list, k=100):\n",
    "    \"\"\"\n",
    "    Tính NDCG@K\n",
    "    \n",
    "    Args:\n",
    "        recommended_list: list of recommended movie IDs\n",
    "        relevant_list: list of relevant movie IDs (đã sắp xếp theo rating)\n",
    "        k: cutoff position\n",
    "    \n",
    "    Returns:\n",
    "        NDCG score\n",
    "    \"\"\"\n",
    "    # DCG của recommendation\n",
    "    dcg = calculate_dcg(recommended_list, relevant_list, k)\n",
    "    \n",
    "    # IDCG (ideal DCG) - nếu recommend đúng hết các relevant items\n",
    "    idcg = calculate_dcg(relevant_list, relevant_list, k)\n",
    "    \n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dcg / idcg\n",
    "\n",
    "# Test\n",
    "test_ndcg = calculate_ndcg([1, 2, 3, 4, 5], [3, 1], k=5)\n",
    "print(f\"Test NDCG: {test_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính NDCG cho TF-IDF\n",
    "ndcg_tfidf = calculate_ndcg(recommended_list_tfidf, test_sorted_ids, k=100)\n",
    "\n",
    "print(f\"NDCG@100 for TF-IDF: {ndcg_tfidf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính NDCG cho Word2Vec\n",
    "ndcg_w2v = calculate_ndcg(recommended_list_w2v, test_sorted_ids, k=100)\n",
    "\n",
    "print(f\"NDCG@100 for Word2Vec: {ndcg_w2v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa81686",
   "metadata": {},
   "source": [
    "## 11. So sánh và Kết luận"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1284f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo bảng so sánh\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Precision@100', 'Recall@100', 'F1@100', 'MRR', 'NDCG@100'],\n",
    "    'TF-IDF': [\n",
    "        f\"{metrics_tfidf['precision']:.4f}\",\n",
    "        f\"{metrics_tfidf['recall']:.4f}\",\n",
    "        f\"{metrics_tfidf['f1']:.4f}\",\n",
    "        f\"{mrr_tfidf:.4f}\",\n",
    "        f\"{ndcg_tfidf:.4f}\"\n",
    "    ],\n",
    "    'Word2Vec': [\n",
    "        f\"{metrics_w2v['precision']:.4f}\",\n",
    "        f\"{metrics_w2v['recall']:.4f}\",\n",
    "        f\"{metrics_w2v['f1']:.4f}\",\n",
    "        f\"{mrr_w2v:.4f}\",\n",
    "        f\"{ndcg_w2v:.4f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BẢNG SO SÁNH KẾT QUẢ: TF-IDF vs WORD2VEC\")\n",
    "print(\"=\"*70)\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: P@K, R@K, F1@K\n",
    "metrics_names = ['Precision@100', 'Recall@100', 'F1@100']\n",
    "tfidf_scores = [metrics_tfidf['precision'], metrics_tfidf['recall'], metrics_tfidf['f1']]\n",
    "w2v_scores = [metrics_w2v['precision'], metrics_w2v['recall'], metrics_w2v['f1']]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, tfidf_scores, width, label='TF-IDF', alpha=0.8)\n",
    "axes[0].bar(x + width/2, w2v_scores, width, label='Word2Vec', alpha=0.8)\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Precision, Recall, F1 @ K=100')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics_names)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: MRR và NDCG\n",
    "ranking_metrics = ['MRR', 'NDCG@100']\n",
    "tfidf_ranking = [mrr_tfidf, ndcg_tfidf]\n",
    "w2v_ranking = [mrr_w2v, ndcg_w2v]\n",
    "\n",
    "x2 = np.arange(len(ranking_metrics))\n",
    "\n",
    "axes[1].bar(x2 - width/2, tfidf_ranking, width, label='TF-IDF', alpha=0.8)\n",
    "axes[1].bar(x2 + width/2, w2v_ranking, width, label='Word2Vec', alpha=0.8)\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Ranking Metrics')\n",
    "axes[1].set_xticks(x2)\n",
    "axes[1].set_xticklabels(ranking_metrics)\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746478e7",
   "metadata": {},
   "source": [
    "## 12. Nhận xét và Kết luận"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0280d9f",
   "metadata": {},
   "source": [
    "### Nhận xét:\n",
    "\n",
    "#### 1. **So sánh hiệu suất:**\n",
    "\n",
    "**TF-IDF:**\n",
    "- **Ưu điểm:**\n",
    "  - Nhanh và hiệu quả về mặt tính toán\n",
    "  - Dễ hiểu và triển khai\n",
    "  - Hiệu quả với dữ liệu có cấu trúc rõ ràng\n",
    "  - Bắt được các từ khóa quan trọng và đặc trưng\n",
    "\n",
    "- **Nhược điểm:**\n",
    "  - Không bắt được ý nghĩa ngữ nghĩa (semantic meaning)\n",
    "  - Không xử lý được từ đồng nghĩa\n",
    "  - Ma trận thưa (sparse matrix) có thể dẫn đến mất thông tin\n",
    "\n",
    "**Word2Vec:**\n",
    "- **Ưu điểm:**\n",
    "  - Bắt được mối quan hệ ngữ nghĩa giữa các từ\n",
    "  - Xử lý tốt từ đồng nghĩa và tương tự\n",
    "  - Vector dense (không thưa) giữ được nhiều thông tin\n",
    "  - Có khả năng generalize tốt hơn\n",
    "\n",
    "- **Nhược điểm:**\n",
    "  - Yêu cầu corpus lớn để train tốt\n",
    "  - Phức tạp và tốn thời gian hơn\n",
    "  - Có thể không hiệu quả với corpus nhỏ\n",
    "\n",
    "#### 2. **Kết quả thực nghiệm:**\n",
    "\n",
    "Dựa vào các metrics:\n",
    "- **Precision@100, Recall@100, F1@100**: So sánh khả năng tìm đúng phim trong test set\n",
    "- **MRR**: Đánh giá vị trí của phim relevant đầu tiên\n",
    "- **NDCG@100**: Đánh giá chất lượng ranking tổng thể\n",
    "\n",
    "#### 3. **Kết luận:**\n",
    "\n",
    "- Nếu TF-IDF có metrics cao hơn → phù hợp hơn cho bài toán này với dataset có sẵn\n",
    "- Nếu Word2Vec tốt hơn → khả năng bắt semantic similarity tốt hơn cho recommend\n",
    "- Có thể kết hợp cả 2 phương pháp (ensemble) để tận dụng ưu điểm của mỗi phương pháp\n",
    "\n",
    "#### 4. **Đề xuất cải thiện:**\n",
    "\n",
    "1. **Hybrid approach**: Kết hợp TF-IDF và Word2Vec với weight\n",
    "2. **Fine-tune Word2Vec**: Điều chỉnh hyperparameters (vector_size, window, min_count)\n",
    "3. **Thêm features**: Kết hợp thêm genres, keywords, actors\n",
    "4. **Ensemble learning**: Sử dụng voting hoặc stacking\n",
    "5. **Deep Learning**: Sử dụng BERT, Doc2Vec hoặc neural embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ae671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In summary cuối cùng\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TÓM TẮT KẾT QUẢ THỰC NGHIỆM\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n1. User ID: 201\")\n",
    "print(f\"2. Tổng số phim đã đánh giá: {len(user_201_ratings)}\")\n",
    "print(f\"3. Số phim sử dụng: 110\")\n",
    "print(f\"   - Test set: 100 phim\")\n",
    "print(f\"   - Profile set: 10 phim\")\n",
    "print(f\"\\n4. Phương pháp đánh giá:\")\n",
    "print(f\"   - Content-Based Filtering với TF-IDF\")\n",
    "print(f\"   - Content-Based Filtering với Word2Vec\")\n",
    "print(f\"\\n5. Metrics sử dụng:\")\n",
    "print(f\"   - Precision@100, Recall@100, F1@100\")\n",
    "print(f\"   - MRR (Mean Reciprocal Rank)\")\n",
    "print(f\"   - NDCG@100 (Normalized Discounted Cumulative Gain)\")\n",
    "\n",
    "print(f\"\\n6. Kết quả:\")\n",
    "print(f\"\\n   TF-IDF:\")\n",
    "print(f\"   - True Positives: {metrics_tfidf['true_positives']}\")\n",
    "print(f\"   - Precision@100: {metrics_tfidf['precision']:.4f}\")\n",
    "print(f\"   - Recall@100: {metrics_tfidf['recall']:.4f}\")\n",
    "print(f\"   - F1@100: {metrics_tfidf['f1']:.4f}\")\n",
    "print(f\"   - MRR: {mrr_tfidf:.4f}\")\n",
    "print(f\"   - NDCG@100: {ndcg_tfidf:.4f}\")\n",
    "\n",
    "print(f\"\\n   Word2Vec:\")\n",
    "print(f\"   - True Positives: {metrics_w2v['true_positives']}\")\n",
    "print(f\"   - Precision@100: {metrics_w2v['precision']:.4f}\")\n",
    "print(f\"   - Recall@100: {metrics_w2v['recall']:.4f}\")\n",
    "print(f\"   - F1@100: {metrics_w2v['f1']:.4f}\")\n",
    "print(f\"   - MRR: {mrr_w2v:.4f}\")\n",
    "print(f\"   - NDCG@100: {ndcg_w2v:.4f}\")\n",
    "\n",
    "# Xác định phương pháp tốt hơn\n",
    "if metrics_tfidf['f1'] > metrics_w2v['f1']:\n",
    "    winner = \"TF-IDF\"\n",
    "    winner_f1 = metrics_tfidf['f1']\n",
    "elif metrics_w2v['f1'] > metrics_tfidf['f1']:\n",
    "    winner = \"Word2Vec\"\n",
    "    winner_f1 = metrics_w2v['f1']\n",
    "else:\n",
    "    winner = \"Ngang nhau\"\n",
    "    winner_f1 = metrics_tfidf['f1']\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"KẾT LUẬN: Phương pháp {winner} cho kết quả tốt hơn với F1@100 = {winner_f1:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
